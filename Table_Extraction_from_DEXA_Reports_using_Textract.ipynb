{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LP7AGpHX66lo"
   },
   "source": [
    "# **OCR DXA Reports Using AWS Textract**\n",
    "\n",
    "**<h2>Overview</h2>**<br/>\n",
    "This notebook can be employed to extracts text and data from <strong>DICOM report images</strong>(In my Case, DXA Reports). <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bv7BYtdQD1tP"
   },
   "source": [
    "### **Phase 1 - Read DICOM files**\n",
    "\n",
    "> First, We need to install *pydicom* to read DICOM files. *pydicom* is a pure Python package for working with DICOM files. <br/>We will access particular elements in DICOM dataset and print them to .csv files. <br/>For more information about *pydicom*, click [here](https://pydicom.github.io/pydicom/stable/old/getting_started.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change working directory\n",
    "import os\n",
    "os.chdir('F:/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "imYom45fSRde",
    "outputId": "eacf57c5-6bb6-47d0-a0ed-1d2c9ef61017",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run C:/Users/mchoi/Desktop/dicom/read_dicom.py --infile=DXA --outfile=DXA.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EtaucycN-J-b"
   },
   "source": [
    "### **Phase 2 - Convert DCM to PNG**\n",
    "\n",
    "> Second, We need to convert .dcm to .png format. Let's import some libraries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMTHRHpq-JZX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import concurrent.futures\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from pydicom.pixel_data_handlers.util import apply_color_lut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wc0LI31abdch"
   },
   "source": [
    "Load the csv file we made in <strong>Phase 1</strong> , and make a new Dataframe using pandas. Make new directories and save data grouped by our criteria, 'SeriesDescription' and 'ProtocolName'. Converted .png files will be saved in directories hierarchically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_imgs(key, group):\n",
    "\n",
    "    # path = os.path.join(key[0],key[1])\n",
    "    path = key\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    # print(key)\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(chunk_process, lst, path) for lst in chunks(group['filename'].values, 2000)]\n",
    "        for idx, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "            res = future.result()\n",
    "            print(f\"chunk_process Job#{idx}, result: {res}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_process(lst, path):\n",
    "    already = os.listdir(path)\n",
    "    for f in tqdm(lst):\n",
    "        filename = f.replace(\"\\\\\",\"_\").replace(\".dcm\",'.png')\n",
    "        if filename in already:\n",
    "            continue\n",
    "        else:\n",
    "            des = os.path.join(path,filename)\n",
    "            ds = pydicom.dcmread(f)\n",
    "            arr = ds.pixel_array\n",
    "            if 'RGB' in ds.PhotometricInterpretation:\n",
    "                plt.imsave(des,arr)\n",
    "            elif 'PALETTE' in ds.PhotometricInterpretation:\n",
    "                rgb = apply_color_lut(arr,ds)\n",
    "                cv2.imwrite(des, rgb)\n",
    "            elif 'MONOCHROME' in ds.PhotometricInterpretation:\n",
    "                plt.imsave(des,arr,cmap='gray')\n",
    "            else:\n",
    "                print(f'{f}: {ds.PhotometricInterpretation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "LIt18fb96oj5",
    "outputId": "6682d189-5c5b-4253-9da5-3f638a30560a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/mchoi/Desktop/1234/DXA.csv\", encoding='utf-8')\n",
    "#data = pd.read_excel('2013.xlsx', header= 0)\n",
    "# df = data[['filename','SeriesDescription','ProtocolName']]\n",
    "df = data[['filename','ProtocolName']]\n",
    "# df['SeriesDescription'] = df['SeriesDescription'].fillna(\"None\")\n",
    "df = df[df['ProtocolName'] == 'Left Femur']\n",
    "\n",
    "# grouped = df.groupby(['SeriesDescription', 'ProtocolName'])\n",
    "grouped = df.groupby('ProtocolName')\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(make_imgs, key, group) for key,group in grouped]\n",
    "    for idx, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "        res = future.result()\n",
    "        print(\"make_imgs Job#\", idx, \"result \", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpzXqGrofSiy"
   },
   "source": [
    "### **Phase 3 - Extract text from Image using AWS Textract**\n",
    "\n",
    "\n",
    "> Let's extract our data quickly by using Textract. We're going to make Textract to detect text synchronously, use the 'DetectDocumentText' API operation. The results are returned in JSON structure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_textract(lst):\n",
    "    for filename in tqdm(lst):\n",
    "        with open(filename, 'rb') as file:\n",
    "            imageBytes = bytearray(file.read())\n",
    "\n",
    "            client = boto3.client(service_name = 'textract',\n",
    "                                 region_name = 'us-east-1')\n",
    "\n",
    "            # Detect text in the document\n",
    "            \n",
    "            try:\n",
    "                response = client.detect_document_text(Document={'Bytes': imageBytes})\n",
    "                with open('./json/'+filename.split('\\\\')[-1]+'.json', mode='w', encoding='utf-8')as f:\n",
    "                    json.dump(response,f )\n",
    "            except:\n",
    "                print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "\n",
    "file_dir = 'F:/Left Femur'\n",
    "\n",
    "os.chdir(file_dir)\n",
    "print(f'Now in {os.getcwd()}')\n",
    "os.makedirs('json', exist_ok=True)\n",
    "\n",
    "filelst = os.listdir(file_dir)\n",
    "pnglst = [f for f in filelst if '.png' in f]\n",
    "jsonlst = [j[:-5] for j in os.listdir(os.path.join(file_dir,'json'))]\n",
    "# jsonlst = tmp\n",
    "target = list(set(pnglst)-set(jsonlst))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(do_textract, lst) for lst in chunks(target, 1050)]\n",
    "    for idx, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "        res = future.result()\n",
    "        print(\"Proccessed Job \", idx, \"result \", res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Phase 4 - Export Tabular Data into a CSV File**\n",
    "\n",
    "\n",
    "> We don't need all texts from images. We only need data stored in tables.  Textract returns the location of the lines and words, so we are going to use it to extract essential data. You can skip this step if you use 'AnalyzeDocument' API in previous step, not 'DetectDocumentText' API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run C:/Users/mchoi/Desktop/dicom/json_parser.py --path=\"F:/Left Femur/json\""
   ]
  },
  {
   "source": [
    "## Intermission\n",
    "OCR results is not 100% accurate.\n",
    "Open the output.csv file in Google Spreadsheet and check the values. \n",
    "You may get an error in the next step if quality check isn't done properly."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### **Phase 5 - Reshape data based on column of the CSV File**\n",
    "\n",
    "\n",
    "> Read json/output.csv into pandas DataFrame. We are going to reshape data based on 'Region' column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run C:/Users/mchoi/Desktop/dicom/csv_parser.py\" --infile \"F:/Left Femur/json/output.csv\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "R92sbgC9ifW6"
   ],
   "name": "DicomOcrUsingTextract .ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 32-bit",
   "language": "python",
   "name": "python38332bit355610f755fd4ca5999aecfbf36ab63c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "637c701f654a44e9b93663e3f0d2c3e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "672427e3b8334c58b260bf65a2367b01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6d0d0aa8012b4addbc076db10eeddb17",
       "IPY_MODEL_9e867bd26da04adca8b276dab435e9b4"
      ],
      "layout": "IPY_MODEL_637c701f654a44e9b93663e3f0d2c3e9"
     }
    },
    "6d0d0aa8012b4addbc076db10eeddb17": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93c2cdae9d9149778d0719a35406fa60",
      "max": 148,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5dd00d8bb6545f7b427fe00f98cb8d8",
      "value": 148
     }
    },
    "727f9fa9aec7450eaf16411c6ca1ba0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93c2cdae9d9149778d0719a35406fa60": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e867bd26da04adca8b276dab435e9b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc6f6b10556d4c0984cc666b4f382064",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_727f9fa9aec7450eaf16411c6ca1ba0b",
      "value": " 148/148 [12:07&lt;00:00,  4.91s/it]"
     }
    },
    "cc6f6b10556d4c0984cc666b4f382064": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5dd00d8bb6545f7b427fe00f98cb8d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}